<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Teem KWONG">
<meta name="dcterms.date" content="2026-01-17">

<title>How Does Chain-of-Thought (CoT) Prompting Influence the Outputs of Large Language Models (LLMs)? – Teem KWONG’s website</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-2ef4ee80fceeed9d7602223a42239af8.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Teem KWONG’s website</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction-the-black-box-problem" id="toc-introduction-the-black-box-problem" class="nav-link active" data-scroll-target="#introduction-the-black-box-problem">Introduction: The “Black Box” Problem</a></li>
  <li><a href="#what-is-chain-of-thought-cot-prompting" id="toc-what-is-chain-of-thought-cot-prompting" class="nav-link" data-scroll-target="#what-is-chain-of-thought-cot-prompting">What is Chain-of-Thought (CoT) Prompting?</a>
  <ul class="collapse">
  <li><a href="#a-comparative-example" id="toc-a-comparative-example" class="nav-link" data-scroll-target="#a-comparative-example">A Comparative Example</a></li>
  </ul></li>
  <li><a href="#the-technical-why-building-logic-brick-by-brick" id="toc-the-technical-why-building-logic-brick-by-brick" class="nav-link" data-scroll-target="#the-technical-why-building-logic-brick-by-brick">The Technical “Why”: Building Logic Brick by Brick</a>
  <ul class="collapse">
  <li><a href="#logic-decomposition-the-lego-principle" id="toc-logic-decomposition-the-lego-principle" class="nav-link" data-scroll-target="#logic-decomposition-the-lego-principle">1. Logic Decomposition: The LEGO Principle</a></li>
  <li><a href="#externalizing-working-memory" id="toc-externalizing-working-memory" class="nav-link" data-scroll-target="#externalizing-working-memory">2. Externalizing “Working Memory”</a></li>
  <li><a href="#error-correction-catching-the-misplaced-brick" id="toc-error-correction-catching-the-misplaced-brick" class="nav-link" data-scroll-target="#error-correction-catching-the-misplaced-brick">3. Error Correction: Catching the “Misplaced Brick”</a></li>
  </ul></li>
  <li><a href="#variations-of-the-cot-pattern" id="toc-variations-of-the-cot-pattern" class="nav-link" data-scroll-target="#variations-of-the-cot-pattern">Variations of the CoT Pattern</a>
  <ul class="collapse">
  <li><a href="#zero-shot-cot-the-magic-instruction" id="toc-zero-shot-cot-the-magic-instruction" class="nav-link" data-scroll-target="#zero-shot-cot-the-magic-instruction">1. Zero-Shot CoT: The “Magic” Instruction</a></li>
  <li><a href="#few-shot-cot-exemplar-based-reasoning" id="toc-few-shot-cot-exemplar-based-reasoning" class="nav-link" data-scroll-target="#few-shot-cot-exemplar-based-reasoning">2. Few-Shot CoT: Exemplar-Based Reasoning</a></li>
  <li><a href="#self-consistency-voting-for-accuracy" id="toc-self-consistency-voting-for-accuracy" class="nav-link" data-scroll-target="#self-consistency-voting-for-accuracy">3. Self-Consistency: Voting for Accuracy</a></li>
  </ul></li>
  <li><a href="#practical-case-study-automating-data-cleaning" id="toc-practical-case-study-automating-data-cleaning" class="nav-link" data-scroll-target="#practical-case-study-automating-data-cleaning">Practical Case Study: Automating Data Cleaning</a></li>
  <li><a href="#advantages-and-limitations" id="toc-advantages-and-limitations" class="nav-link" data-scroll-target="#advantages-and-limitations">Advantages and Limitations</a>
  <ul class="collapse">
  <li><a href="#the-benefits" id="toc-the-benefits" class="nav-link" data-scroll-target="#the-benefits">The Benefits</a></li>
  <li><a href="#the-trade-offs" id="toc-the-trade-offs" class="nav-link" data-scroll-target="#the-trade-offs">The Trade-offs</a></li>
  </ul></li>
  <li><a href="#conclusion-the-path-forward" id="toc-conclusion-the-path-forward" class="nav-link" data-scroll-target="#conclusion-the-path-forward">Conclusion: The Path Forward</a>
  <ul class="collapse">
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">How Does Chain-of-Thought (CoT) Prompting Influence the Outputs of Large Language Models (LLMs)?</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Teem KWONG </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 17, 2026</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="introduction-the-black-box-problem" class="level2">
<h2 class="anchored" data-anchor-id="introduction-the-black-box-problem">Introduction: The “Black Box” Problem</h2>
<p>In the early days of Large Language Model (LLM) adoption, users often treated models like GPT-3 or early Gemini versions as sophisticated search engines. We provided a query, and the model returned a result. This works perfectly for retrieving facts: “What is the boiling point of nitrogen?” results in a quick, accurate answer.</p>
<p>However, as we moved toward more complex tasks, like solving word problems or planning a multi-step schedule, the “Black Box” nature of LLMs became a liability. Imagine asking the model: <em>“If I buy 3 apples for $2 each and a $10 cake, how much change do I get from $20?”</em> A model might confidently blurt out <strong>“$8”</strong> because it recognized the numbers with dollar sign but “hallucinated” a shortcut, completely forgetting 3 apples. Without seeing the steps, you have no idea where the math went wrong. It either gives you the right destination or leaves you stranded in the wrong place with no map in between.</p>
<p>The breakthrough came when researchers realized that LLMs, much like human students, perform significantly better when they are forced to “show their work.” This technique, known as <strong>Chain-of-Thought (CoT) Prompting</strong>, is not just a trick of language, it is a fundamental shift in how we interact with neural networks.</p>
<hr>
</section>
<section id="what-is-chain-of-thought-cot-prompting" class="level2">
<h2 class="anchored" data-anchor-id="what-is-chain-of-thought-cot-prompting">What is Chain-of-Thought (CoT) Prompting?</h2>
<p>Chain-of-Thought prompting is a technique where we ask an AI model to explain its reasoning before giving the answer. Instead of jumping to conclusions, the model unfolds its “thought process” in natural language.</p>
<section id="a-comparative-example" class="level3">
<h3 class="anchored" data-anchor-id="a-comparative-example">A Comparative Example</h3>
<p>Consider the following logic puzzle: &gt; <em>Question: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?</em></p>
<p><strong>Standard Prompting Output:</strong> &gt; <em>Answer: 7.</em> (Incorrect)</p>
<p><strong>CoT Prompting Output:</strong> &gt;</p>
<p><em>Step 1: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls.</em></p>
<p><em>Step 2: 5 + 6 = 11.</em></p>
<p><em>Step 3: The answer is 11.</em></p>
<p><em>Answer: 11.</em> (Incorrect)</p>
<p>In this case, the model followed the logical flow. By generating the text for Step 1, the model created a “new” context for Step 2. It no longer had to remember <em>2 cans of 3 tennis balls</em>; it only had to focus on the result “6” that was now physically present in its recent memory.</p>
<p><img src="img/q3_1.png" class="img-fluid"></p>
<p>Image Source: <a href="https://arxiv.org/abs/2201.11903">Wei et al.&nbsp;(2022)</a></p>
<hr>
</section>
</section>
<section id="the-technical-why-building-logic-brick-by-brick" class="level2">
<h2 class="anchored" data-anchor-id="the-technical-why-building-logic-brick-by-brick">The Technical “Why”: Building Logic Brick by Brick</h2>
<p>To understand why CoT works, we have to look under the hood of how Large Language Models process information. LLMs predict the next word (or “token”) based on everything that came before it. In a standard prompt, the model tries to leap from the question to the final answer in one go. This is where logic often breaks down.</p>
<section id="logic-decomposition-the-lego-principle" class="level3">
<h3 class="anchored" data-anchor-id="logic-decomposition-the-lego-principle">1. Logic Decomposition: The LEGO Principle</h3>
<p>CoT prompting works because it encourages logic decomposition—breaking a massive, intimidating problem into smaller, manageable parts. Think of it like building a complex LEGO castle. You wouldn’t try to manifest the entire castle at once; you’d follow the manual to build the baseplate, then the walls, then the towers.</p>
<p>This “divide and conquer” approach is essential for solving long word problems, planning detailed essays, or diagnosing software bugs. By constructing these smaller “logical blocks” first, the model can eventually snap them all together to form a complete, sturdy structure.</p>
</section>
<section id="externalizing-working-memory" class="level3">
<h3 class="anchored" data-anchor-id="externalizing-working-memory">2. Externalizing “Working Memory”</h3>
<p>In a standard prompt, the model has to perform all its “thinking” inside its hidden layers before it types a single letter. This is like trying to solve a 10-digit multiplication problem entirely in your head without a piece of paper. You’re likely to lose track of a carry-over digit and fail.</p>
<p>When a model writes down a reasoning step, it’s like placing a LEGO brick firmly into the baseplate. Once that brick is placed, the model can “see” it. It no longer has to use its internal “mental energy” to remember that specific sub-step because it is now part of the written text. This process acts as external working memory, allowing the model to “read” its own previous logic to inform what comes next.</p>
</section>
<section id="error-correction-catching-the-misplaced-brick" class="level3">
<h3 class="anchored" data-anchor-id="error-correction-catching-the-misplaced-brick">3. Error Correction: Catching the “Misplaced Brick”</h3>
<p>One of the greatest strengths of the LEGO approach is error locality. If you are building a LEGO tower and you put a 2x4 brick where a 2x2 brick should be, you will notice the misalignment immediately as you try to add the next layer.</p>
<p>Similarly, when an LLM explains its intermediate reasoning, it is much easier to catch mistakes early. If the model realizes in Step 2 that its math doesn’t add up, the “physical” presence of that error in the text window often nudges the model to self-correct before it reaches the final answer. This leads to far more consistent and accurate results than a single “black box” guess.</p>
<hr>
</section>
</section>
<section id="variations-of-the-cot-pattern" class="level2">
<h2 class="anchored" data-anchor-id="variations-of-the-cot-pattern">Variations of the CoT Pattern</h2>
<p>As the field of Prompt Engineering has matured, three primary variations of CoT have emerged as industry standards.</p>
<section id="zero-shot-cot-the-magic-instruction" class="level3">
<h3 class="anchored" data-anchor-id="zero-shot-cot-the-magic-instruction">1. Zero-Shot CoT: The “Magic” Instruction</h3>
<p>Here, you simply add a phrase like “Let’s think step by step” to a question. The model interprets this as an instruction to explain its reasoning, i.e.&nbsp;no examples needed.</p>
<p><img src="img/q3_2.png" class="img-fluid"></p>
<p>Image Source: <a href="https://arxiv.org/abs/2205.11916">Kojima et al.&nbsp;(2022)</a></p>
</section>
<section id="few-shot-cot-exemplar-based-reasoning" class="level3">
<h3 class="anchored" data-anchor-id="few-shot-cot-exemplar-based-reasoning">2. Few-Shot CoT: Exemplar-Based Reasoning</h3>
<p>This version provides a few examples of problems and their worked-out solutions before the new question. It’s like giving a student a few solved examples before letting them try on their own.</p>
</section>
<section id="self-consistency-voting-for-accuracy" class="level3">
<h3 class="anchored" data-anchor-id="self-consistency-voting-for-accuracy">3. Self-Consistency: Voting for Accuracy</h3>
<p>Self-consistency: Instead of relying on a single chain of thought, the model generates multiple reasoning paths, then picks the most consistent conclusion. This reduces random errors and produces more reliable results.</p>
<hr>
</section>
</section>
<section id="practical-case-study-automating-data-cleaning" class="level2">
<h2 class="anchored" data-anchor-id="practical-case-study-automating-data-cleaning">Practical Case Study: Automating Data Cleaning</h2>
<p>Let’s look at a real-world Data Science application. Imagine you have a messy dataset and you need an LLM to write a Python script to clean it.</p>
<p><strong>Standard Prompt:</strong> &gt; “Write a Python script to clean this CSV where ‘Date’ is in various formats and ‘Income’ has currency symbols.”</p>
<p>The model might write a quick script that misses certain edge cases, like “€” versus “$”.</p>
<p><strong>CoT Prompt:</strong> &gt; “Let’s approach this data cleaning task systematically. First, identify all possible date formats. Second, determine the best regex for stripping currency symbols. Third, handle missing values. Finally, write the script.”</p>
<p>By following this chain, the model is much more likely to produce robust code that accounts for the nuances of the data, as it has “thought through” the edge cases before it even began writing the first line of <code>import pandas as pd</code>.</p>
<hr>
</section>
<section id="advantages-and-limitations" class="level2">
<h2 class="anchored" data-anchor-id="advantages-and-limitations">Advantages and Limitations</h2>
<section id="the-benefits" class="level3">
<h3 class="anchored" data-anchor-id="the-benefits">The Benefits</h3>
<ol type="1">
<li><strong>Enhanced Logical Transparency:</strong> CoT transforms the AI from a “black box” into an open book. Especially in complex fields like medical diagnostics or financial forecasting, it provides a clear reasoning chain of logic. Instead of just receiving a final number or statement, you can see exactly how the AI arrived at its conclusion.</li>
<li><strong>Precision in Complex Reasoning:</strong> This approach is most powerful when tackling mathematical problems, strategic planning, or multi-step logic. By breaking down the process, the model stays “on track” during long-form generation, ensuring that the final output is grounded in a consistent, step-by-step methodology.</li>
<li><strong>Educational Insight:</strong> Beyond simply providing an answer, CoT serves as an instructional tool. It teaches the user the underlying methodology, showing the “how” and “why” behind a solution. This makes it an invaluable resource for learning how to approach similar strategic or logical challenges in the future.</li>
</ol>
</section>
<section id="the-trade-offs" class="level3">
<h3 class="anchored" data-anchor-id="the-trade-offs">The Trade-offs</h3>
<ol type="1">
<li><strong>Increased Resource Overhead:</strong> The primary cost of detailed reasoning is a higher token count. Because CoT generates full reasoning chains rather than just a final result, it consumes significantly more computational power.</li>
<li><strong>Latency &amp; Speed Constraints:</strong> In environments where “speed is king,” CoT can be a bottleneck. Generating several paragraphs of logic takes more time than a concise one-sentence answer. This makes it unsuitable for real-time chatbots or simple queries, like weather updates or basic definitions, where the extra “thinking time” creates unnecessary delays for the user.</li>
</ol>
<hr>
</section>
</section>
<section id="conclusion-the-path-forward" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-the-path-forward">Conclusion: The Path Forward</h2>
<p>Chain-of-Thought (CoT) prompting marks a fundamental shift in AI, evolving Large Language Models from simple “answer machines” into sophisticated reasoning engines. By making the model’s logic transparent and interpretable, CoT builds the necessary trust for AI integration in professional and academic environments.</p>
<p>For data scientists and enthusiasts alike, mastering CoT is essential. It serves as the bridge between superficial fluency and true logical depth, ensuring that the AI of the future is not only more accurate but also more transparent and reliable.</p>
<hr>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">References</h3>
<p>Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E. H., Le, Q. V., &amp; Zhou, D. (2022). <a href="https://arxiv.org/abs/2201.11903">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</a>. <em>arXiv preprint arXiv:2201.11903</em>.</p>
<p>Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., &amp; Iwasawa, Y. (2022). <a href="https://doi.org/10.48550/arXiv.2205.11916">Large language models are zero-shot reasoners</a>. <em>arXiv preprint arXiv:2205.11916</em></p>
<p>Chain-of-Thought (CoT) Prompting. (n.d.). <em>Prompting Guide</em>. Retrieved January 7, 2026, from <a href="https://www.promptingguide.ai/techniques/cot/" class="uri">https://www.promptingguide.ai/techniques/cot/</a></p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/mdskwong\.github\.io\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>